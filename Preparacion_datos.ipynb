{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1ac31a",
   "metadata": {},
   "source": [
    "## Preparación y Unificación de Datasets de Salarios\n",
    "### 1. Carga y Limpieza Inicial de los Datasets\n",
    "\n",
    "Cargamos los datasets y aplicamos la limpieza básica identificada en el EDA previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fcc66f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in /opt/homebrew/Caskroom/miniconda/base/envs/.conda/lib/python3.10/site-packages (24.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8c1e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de Dataset 1 después de limpieza inicial: (565, 11)\n",
      "Forma de Dataset 2 después de limpieza inicial: (5341, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry\n",
    "\n",
    "try:\n",
    "    df1_original = pd.read_csv(\"./data_source/ds_salaries.csv\")\n",
    "    df2_original = pd.read_csv(\"./data_source/jobs_in_data.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Uno o ambos archivos CSV no se encontraron. Verifica las rutas: ./data_source/\")\n",
    "    # Crear dataframes vacíos para evitar errores si los archivos no se encuentran\n",
    "    df1_original = pd.DataFrame()\n",
    "    df2_original = pd.DataFrame()\n",
    "\n",
    "df1 = df1_original.copy()\n",
    "df2 = df2_original.copy()\n",
    "\n",
    "# Limpieza Dataset 1 (ds_salaries.csv)\n",
    "if 'Unnamed: 0' in df1.columns:\n",
    "    df1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df1.drop_duplicates(inplace=True)\n",
    "print(f\"Forma de Dataset 1 después de limpieza inicial: {df1.shape}\")\n",
    "\n",
    "# Limpieza Dataset 2 (jobs_in_data.csv)\n",
    "if 'job_category' in df2.columns:  # Esta columna no existe en ds_salaries\n",
    "    df2.drop(['job_category'], axis=1, inplace=True)\n",
    "df2.drop_duplicates(inplace=True)\n",
    "print(f\"Forma de Dataset 2 después de limpieza inicial: {df2.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23ed3a",
   "metadata": {},
   "source": [
    "### 2. Estandarización de Columnas Comunes\n",
    "\n",
    "Ahora, unificaremos los valores de las columnas que tienen diferentes formatos.\n",
    "\n",
    "#### 2.1. `experience_level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17fd4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos de 'experience_level' en df1 después de mapeo:\n",
      "experience_level\n",
      "Senior         243\n",
      "Mid-level      208\n",
      "Entry-level     88\n",
      "Executive       26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos de 'experience_level' en df2 (sin cambios esperados):\n",
      "experience_level\n",
      "Senior         3444\n",
      "Mid-level      1274\n",
      "Entry-level     400\n",
      "Executive       223\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if not df1.empty:\n",
    "    # Mapeo para dataset1\n",
    "    exp_level_map_df1 = {\n",
    "        'EN': 'Entry-level',\n",
    "        'MI': 'Mid-level',\n",
    "        'SE': 'Senior',\n",
    "        'EX': 'Executive'\n",
    "    }\n",
    "    df1['experience_level'] = df1['experience_level'].map(exp_level_map_df1).fillna(df1['experience_level'])\n",
    "    print(\"Valores únicos de 'experience_level' en df1 después de mapeo:\")\n",
    "    print(df1['experience_level'].value_counts())\n",
    "\n",
    "if not df2.empty:\n",
    "    # Para df2, los valores ya deberían ser descriptivos. Solo mostramos para confirmar.\n",
    "    print(\"\\nValores únicos de 'experience_level' en df2 (sin cambios esperados):\")\n",
    "    print(df2['experience_level'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92b16c",
   "metadata": {},
   "source": [
    "#### 2.2. `employment_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3278b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos de 'employment_type' en df1 después de mapeo:\n",
      "employment_type\n",
      "Full-time    546\n",
      "Part-time     10\n",
      "Contract       5\n",
      "Freelance      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos de 'employment_type' en df2 (sin cambios esperados):\n",
      "employment_type\n",
      "Full-time    5296\n",
      "Contract       19\n",
      "Part-time      15\n",
      "Freelance      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if not df1.empty:\n",
    "    # Mapeo para dataset1\n",
    "    emp_type_map_df1 = {\n",
    "        'PT': 'Part-time',\n",
    "        'FT': 'Full-time',\n",
    "        'CT': 'Contract',\n",
    "        'FL': 'Freelance'\n",
    "    }\n",
    "    df1['employment_type'] = df1['employment_type'].map(emp_type_map_df1).fillna(df1['employment_type'])\n",
    "    print(\"Valores únicos de 'employment_type' en df1 después de mapeo:\")\n",
    "    print(df1['employment_type'].value_counts())\n",
    "\n",
    "if not df2.empty:\n",
    "    # Para df2, asumimos que los valores ya son descriptivos (ej. 'Full-time').\n",
    "    # Si hubiera variaciones como 'Full Time', se necesitaría un mapeo adicional aquí.\n",
    "    print(\"\\nValores únicos de 'employment_type' en df2 (sin cambios esperados):\")\n",
    "    print(df2['employment_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5ff01",
   "metadata": {},
   "source": [
    "#### 2.3. `employee_residence` y `company_location`\n",
    "\n",
    "Convertiremos los códigos de país de `dataset1` a nombres completos usando `pycountry`. `dataset2` ya tiene nombres completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23963cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformando códigos de país a nombres en df1...\n",
      "Primeros ejemplos de 'employee_residence' en df1 después de transformación:\n",
      "0           Germany\n",
      "1             Japan\n",
      "2    United Kingdom\n",
      "3          Honduras\n",
      "4     United States\n",
      "Name: employee_residence, dtype: object\n",
      "Primeros ejemplos de 'company_location' en df1 después de transformación:\n",
      "0           Germany\n",
      "1             Japan\n",
      "2    United Kingdom\n",
      "3          Honduras\n",
      "4     United States\n",
      "Name: company_location, dtype: object\n",
      "\n",
      "Primeros ejemplos de 'employee_residence' en df2 (sin cambios esperados):\n",
      "0          Germany\n",
      "1    United States\n",
      "2    United States\n",
      "3    United States\n",
      "4    United States\n",
      "Name: employee_residence, dtype: object\n",
      "Primeros ejemplos de 'company_location' en df2 (sin cambios esperados):\n",
      "0          Germany\n",
      "1    United States\n",
      "2    United States\n",
      "3    United States\n",
      "4    United States\n",
      "Name: company_location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def code_to_country_name(code):\n",
    "    if not pycountry or pd.isna(code) or not isinstance(code, str) or len(code) != 2:\n",
    "        return code  # Devuelve el código original si no es un código válido o pycountry no está disponible\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=code)\n",
    "        return country.name if country else code\n",
    "    except Exception:\n",
    "        return code  # En caso de error, devuelve el código original\n",
    "\n",
    "if not df1.empty and pycountry is not None:\n",
    "    print(\"\\nTransformando códigos de país a nombres en df1...\")\n",
    "    df1['employee_residence'] = df1['employee_residence'].apply(code_to_country_name)\n",
    "    df1['company_location'] = df1['company_location'].apply(code_to_country_name)\n",
    "    print(\"Primeros ejemplos de 'employee_residence' en df1 después de transformación:\")\n",
    "    print(df1['employee_residence'].head())\n",
    "    print(\"Primeros ejemplos de 'company_location' en df1 después de transformación:\")\n",
    "    print(df1['company_location'].head())\n",
    "elif pycountry is None:\n",
    "    print(\"\\npycountry no está disponible, no se transformarán los códigos de país en df1.\")\n",
    "\n",
    "if not df2.empty:\n",
    "    # Solo mostramos ejemplos de df2, ya que se asume que tienen nombres completos.\n",
    "    print(\"\\nPrimeros ejemplos de 'employee_residence' en df2 (sin cambios esperados):\")\n",
    "    print(df2['employee_residence'].head())\n",
    "    print(\"Primeros ejemplos de 'company_location' en df2 (sin cambios esperados):\")\n",
    "    print(df2['company_location'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51d7c6",
   "metadata": {},
   "source": [
    "#### 2.4. `remote_ratio` (dataset1) y `work_setting` (dataset2)\n",
    "\n",
    "Unificaremos esto en una única columna llamada `work_setting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5878dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos de 'work_setting' (originada de 'remote_ratio') en df1 después de mapeo:\n",
      "work_setting\n",
      "Remote       346\n",
      "In-person    121\n",
      "Hybrid        98\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos de 'work_setting' en df2 (sin cambios esperados):\n",
      "work_setting\n",
      "In-person    2913\n",
      "Remote       2239\n",
      "Hybrid        189\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if not df1.empty and 'remote_ratio' in df1.columns:\n",
    "    # Mapeo para dataset1\n",
    "    remote_ratio_map_df1 = {\n",
    "        0: 'In-person',\n",
    "        50: 'Hybrid',\n",
    "        100: 'Remote'\n",
    "    }\n",
    "    df1['work_setting'] = df1['remote_ratio'].map(remote_ratio_map_df1).fillna(df1['remote_ratio'])\n",
    "    df1.drop('remote_ratio', axis=1, inplace=True)\n",
    "    print(\"Valores únicos de 'work_setting' (originada de 'remote_ratio') en df1 después de mapeo:\")\n",
    "    print(df1['work_setting'].value_counts())\n",
    "\n",
    "if not df2.empty and 'work_setting' in df2.columns:\n",
    "    # Para df2, los valores ya deberían ser descriptivos. Solo mostramos para confirmar.\n",
    "    print(\"\\nValores únicos de 'work_setting' en df2 (sin cambios esperados):\")\n",
    "    print(df2['work_setting'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a96f4",
   "metadata": {},
   "source": [
    "### 3. Verificación de Columnas y Concatenación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43c705e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las columnas están alineadas. Procediendo a la concatenación.\n",
      "Forma del dataset unificado: (5906, 11)\n",
      "Duplicados en el dataset unificado: 429\n",
      "Forma del dataset unificado después de eliminar duplicados: (5477, 11)\n",
      "\n",
      "Información del dataset unificado:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5477 entries, 0 to 5876\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           5477 non-null   int64 \n",
      " 1   experience_level    5477 non-null   object\n",
      " 2   employment_type     5477 non-null   object\n",
      " 3   job_title           5477 non-null   object\n",
      " 4   salary              5477 non-null   int64 \n",
      " 5   salary_currency     5477 non-null   object\n",
      " 6   salary_in_usd       5477 non-null   int64 \n",
      " 7   employee_residence  5477 non-null   object\n",
      " 8   company_location    5477 non-null   object\n",
      " 9   company_size        5477 non-null   object\n",
      " 10  work_setting        5477 non-null   object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 513.5+ KB\n",
      "\n",
      "Primeras filas del dataset unificado:\n",
      "   work_year experience_level employment_type                   job_title  \\\n",
      "0       2020        Mid-level       Full-time              Data Scientist   \n",
      "1       2020           Senior       Full-time  Machine Learning Scientist   \n",
      "2       2020           Senior       Full-time           Big Data Engineer   \n",
      "3       2020        Mid-level       Full-time        Product Data Analyst   \n",
      "4       2020           Senior       Full-time   Machine Learning Engineer   \n",
      "\n",
      "   salary salary_currency  salary_in_usd employee_residence company_location  \\\n",
      "0   70000             EUR          79833            Germany          Germany   \n",
      "1  260000             USD         260000              Japan            Japan   \n",
      "2   85000             GBP         109024     United Kingdom   United Kingdom   \n",
      "3   20000             USD          20000           Honduras         Honduras   \n",
      "4  150000             USD         150000      United States    United States   \n",
      "\n",
      "  company_size work_setting  \n",
      "0            L    In-person  \n",
      "1            S    In-person  \n",
      "2            M       Hybrid  \n",
      "3            S    In-person  \n",
      "4            L       Hybrid  \n",
      "\n",
      "Últimas filas del dataset unificado:\n",
      "      work_year experience_level employment_type                 job_title  \\\n",
      "5799       2021           Senior       Full-time            Data Scientist   \n",
      "5809       2021        Mid-level       Full-time             Data Engineer   \n",
      "5828       2021           Senior       Full-time   Data Analytics Engineer   \n",
      "5875       2021        Mid-level       Full-time         Big Data Engineer   \n",
      "5876       2020           Senior       Freelance  Computer Vision Engineer   \n",
      "\n",
      "      salary salary_currency  salary_in_usd employee_residence  \\\n",
      "5799  180000             TRY          20171             Turkey   \n",
      "5809  250000             TRY          28016             Turkey   \n",
      "5828   50000             USD          50000            Vietnam   \n",
      "5875   18000             USD          18000            Moldova   \n",
      "5876   60000             USD          60000             Russia   \n",
      "\n",
      "     company_location company_size work_setting  \n",
      "5799           Turkey            L       Hybrid  \n",
      "5809           Turkey            M       Remote  \n",
      "5828   United Kingdom            M       Remote  \n",
      "5875          Moldova            S    In-person  \n",
      "5876    United States            S       Remote  \n"
     ]
    }
   ],
   "source": [
    "if not df1.empty and not df2.empty:\n",
    "    # Columnas esperadas en el dataset unificado\n",
    "    expected_columns = [\n",
    "        'work_year', 'experience_level', 'employment_type', 'job_title',\n",
    "        'salary', 'salary_currency', 'salary_in_usd', 'employee_residence',\n",
    "        'company_location', 'company_size', 'work_setting'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar columnas según la lista esperada\n",
    "    df1_cols_to_keep = [col for col in expected_columns if col in df1.columns]\n",
    "    df2_cols_to_keep = [col for col in expected_columns if col in df2.columns]\n",
    "    \n",
    "    df1_aligned = df1[df1_cols_to_keep]\n",
    "    df2_aligned = df2[df2_cols_to_keep]\n",
    "    \n",
    "    # Verificar alineación exacta de columnas\n",
    "    if list(df1_aligned.columns) == list(df2_aligned.columns):\n",
    "        print(\"\\nLas columnas están alineadas. Procediendo a la concatenación.\")\n",
    "        df_merged = pd.concat([df1_aligned, df2_aligned], ignore_index=True)\n",
    "        print(f\"Forma del dataset unificado: {df_merged.shape}\")\n",
    "        \n",
    "        # Eliminar duplicados\n",
    "        print(f\"Duplicados en el dataset unificado: {df_merged.duplicated().sum()}\")\n",
    "        df_merged.drop_duplicates(inplace=True)\n",
    "        print(f\"Forma del dataset unificado después de eliminar duplicados: {df_merged.shape}\")\n",
    "        \n",
    "        print(\"\\nInformación del dataset unificado:\")\n",
    "        df_merged.info()\n",
    "        \n",
    "        print(\"\\nPrimeras filas del dataset unificado:\")\n",
    "        print(df_merged.head())\n",
    "        \n",
    "        print(\"\\nÚltimas filas del dataset unificado:\")\n",
    "        print(df_merged.tail())\n",
    "    else:\n",
    "        print(\"\\nError: Las columnas no pudieron ser alineadas completamente.\")\n",
    "        print(f\"Columnas df1: {list(df1_aligned.columns)}\")\n",
    "        print(f\"Columnas df2: {list(df2_aligned.columns)}\")\n",
    "        df_merged = pd.DataFrame()  # Evitar errores posteriores\n",
    "elif df1.empty or df2.empty:\n",
    "    print(\"Uno de los dataframes está vacío. No se puede realizar la unificación.\")\n",
    "    df_merged = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef225e",
   "metadata": {},
   "source": [
    "### 4. Verificación Final de Columnas Unificadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b355dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos y conteos para 'experience_level' en el dataset unificado:\n",
      "experience_level\n",
      "Senior         3468\n",
      "Mid-level      1352\n",
      "Entry-level     427\n",
      "Executive       230\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos y conteos para 'employment_type' en el dataset unificado:\n",
      "employment_type\n",
      "Full-time    5424\n",
      "Contract       20\n",
      "Part-time      20\n",
      "Freelance      13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos y conteos para 'employee_residence' en el dataset unificado:\n",
      "employee_residence\n",
      "United States     4262\n",
      "United Kingdom     380\n",
      "Canada             203\n",
      "Spain               71\n",
      "Germany             69\n",
      "France              56\n",
      "India               41\n",
      "Portugal            29\n",
      "Netherlands         22\n",
      "Australia           21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos y conteos para 'company_location' en el dataset unificado:\n",
      "company_location\n",
      "United States     4317\n",
      "United Kingdom     388\n",
      "Canada             205\n",
      "Germany             77\n",
      "Spain               67\n",
      "France              51\n",
      "India               30\n",
      "Portugal            26\n",
      "Australia           24\n",
      "Netherlands         22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos y conteos para 'work_setting' en el dataset unificado:\n",
      "work_setting\n",
      "In-person    2951\n",
      "Remote       2311\n",
      "Hybrid        215\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if not df_merged.empty:\n",
    "    columns_to_check = ['experience_level', 'employment_type', 'employee_residence', 'company_location', 'work_setting']\n",
    "    for col in columns_to_check:\n",
    "        if col in df_merged.columns:\n",
    "            print(f\"\\nValores únicos y conteos para '{col}' en el dataset unificado:\")\n",
    "            print(df_merged[col].value_counts().head(10))  # Mostrar top 10 para brevedad\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no se encuentra en el dataset unificado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af899626",
   "metadata": {},
   "source": [
    "### 5. Mapeo de variables categoricas con Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5588e637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experience_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "employment_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "job_title",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary_currency",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary_in_usd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "employee_residence",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company_location",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_setting",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "51b81ece-c375-499f-9411-9ccd32638ae5",
       "rows": [
        [
         "0",
         "2020",
         "1",
         "0",
         "71",
         "70000",
         "7",
         "79833",
         "31",
         "25",
         "2",
         "1"
        ],
        [
         "1",
         "2020",
         "2",
         "0",
         "106",
         "260000",
         "16",
         "260000",
         "44",
         "39",
         "0",
         "1"
        ],
        [
         "2",
         "2020",
         "2",
         "0",
         "21",
         "85000",
         "8",
         "109024",
         "86",
         "75",
         "1",
         "0"
        ],
        [
         "3",
         "2020",
         "1",
         "0",
         "119",
         "20000",
         "16",
         "20000",
         "34",
         "29",
         "0",
         "1"
        ],
        [
         "4",
         "2020",
         "2",
         "0",
         "99",
         "150000",
         "16",
         "150000",
         "87",
         "76",
         "2",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>work_setting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>79833</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>260000</td>\n",
       "      <td>16</td>\n",
       "      <td>260000</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>85000</td>\n",
       "      <td>8</td>\n",
       "      <td>109024</td>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>20000</td>\n",
       "      <td>16</td>\n",
       "      <td>20000</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>150000</td>\n",
       "      <td>16</td>\n",
       "      <td>150000</td>\n",
       "      <td>87</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year  experience_level  employment_type  job_title  salary  \\\n",
       "0       2020                 1                0         71   70000   \n",
       "1       2020                 2                0        106  260000   \n",
       "2       2020                 2                0         21   85000   \n",
       "3       2020                 1                0        119   20000   \n",
       "4       2020                 2                0         99  150000   \n",
       "\n",
       "   salary_currency  salary_in_usd  employee_residence  company_location  \\\n",
       "0                7          79833                  31                25   \n",
       "1               16         260000                  44                39   \n",
       "2                8         109024                  86                75   \n",
       "3               16          20000                  34                29   \n",
       "4               16         150000                  87                76   \n",
       "\n",
       "   company_size  work_setting  \n",
       "0             2             1  \n",
       "1             0             1  \n",
       "2             1             0  \n",
       "3             0             1  \n",
       "4             2             0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_job_titles = df_merged['job_title'].unique()\n",
    "job_title_mapping = {title: idx for idx, title in enumerate(sorted(unique_job_titles))}\n",
    "\n",
    "df_merged['job_title'] = df_merged['job_title'].map(job_title_mapping)\n",
    "\n",
    "unique_salary_currency = df_merged['salary_currency'].unique()\n",
    "job_salary_currency_mapping = {title: idx for idx, title in enumerate(sorted(unique_salary_currency))}\n",
    "\n",
    "df_merged['salary_currency'] = df_merged['salary_currency'].map(job_salary_currency_mapping)\n",
    "\n",
    "unique_employee_residence = df_merged['employee_residence'].unique()\n",
    "employee_residence_mapping = {title: idx for idx, title in enumerate(sorted(unique_employee_residence))}\n",
    "\n",
    "df_merged['employee_residence'] = df_merged['employee_residence'].map(employee_residence_mapping)\n",
    "\n",
    "unique_company_location = df_merged['company_location'].unique()\n",
    "company_location_mapping = {title: idx for idx, title in enumerate(sorted(unique_company_location))}\n",
    "\n",
    "df_merged['company_location'] = df_merged['company_location'].map(company_location_mapping)\n",
    "\n",
    "unique_salary_currency = df_merged['salary_currency'].unique()\n",
    "job_salary_currency_mapping = {title: idx for idx, title in enumerate(sorted(unique_salary_currency))}\n",
    "\n",
    "df_merged['salary_currency'] = df_merged['salary_currency'].map(job_salary_currency_mapping)\n",
    "\n",
    "experience_level_mapping = {\n",
    "    'Entry-level': 0,\n",
    "    'Mid-level': 1,\n",
    "    'Senior': 2,\n",
    "    'Executive': 3\n",
    "}\n",
    "df_merged[\"experience_level\"] = df_merged[\"experience_level\"].map(experience_level_mapping)\n",
    "\n",
    "company_size_mapping = {\n",
    "    'S': 0,\n",
    "    'M': 1,\n",
    "    'L': 2\n",
    "}\n",
    "df_merged[\"company_size\"] = df_merged[\"company_size\"].map(company_size_mapping)\n",
    "\n",
    "employment_type_mapping = {\n",
    "    'Full-time': 0,\n",
    "    'Contract': 1,\n",
    "    'Freelance': 2,\n",
    "    'Part-time': 3\n",
    "}\n",
    "\n",
    "df_merged[\"employment_type\"] = df_merged[\"employment_type\"].map(employment_type_mapping)\n",
    "\n",
    "work_setting_mapping = {\n",
    "    'Hybrid': 0,\n",
    "    'In-person': 1,\n",
    "    'Remote': 2,\n",
    "}\n",
    "\n",
    "df_merged[\"work_setting\"] = df_merged[\"work_setting\"].map(work_setting_mapping)\n",
    "\n",
    "# Verificar los cambios\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d5bd8",
   "metadata": {},
   "source": [
    "### 6. Guardar el Dataset Unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "243b39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset unificado guardado exitosamente en: ./data_source/salaries_data_unified.csv\n"
     ]
    }
   ],
   "source": [
    "if not df_merged.empty:\n",
    "    try:\n",
    "        output_path = \"./data_source/salaries_data_unified.csv\"\n",
    "        df_merged.to_csv(output_path, index=False)\n",
    "        print(f\"\\nDataset unificado guardado exitosamente en: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al guardar el dataset unificado: {e}\")\n",
    "else:\n",
    "    print(\"\\nEl dataset unificado está vacío, no se guardará ningún archivo.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
